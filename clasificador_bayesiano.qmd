---
title: "Clasificador Bayesiano de Filtro de Spam"
author: 
  - Tomás Ávila
  - Andrés León
format: html
editor: visual
---

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(tm)
library(e1071)
library(SnowballC)
library(caTools)
library(caret)
library(pROC)
```

# Análisis descriptivo

```{r}
#| include: false
# Cargar datos
df <- read.csv("spam.csv", fileEncoding = "latin1", stringsAsFactors = FALSE)

df <- df %>%
  select(v1, v2) %>%
  rename(label = v1, message = v2)

df$label <- as.factor(df$label)
```

```{r}
# Histograma
ggplot(df, aes(x = label, fill = label)) +
  geom_bar() +
  labs(
    title = "Distribución de Spam vs Ham",
    x = "Categoría",
    y = "Cantidad"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("ham" = "blue", "spam" = "red"))

# Distribución porcentual
knitr::kable(df %>%
  count(label) %>%
  mutate(percentage = n / sum(n) * 100))
```

```{r}
# Longitud del mensaje
df <- df %>%
  mutate(message_length = nchar(message))

# Distribución de la longitud del mensaje
ggplot(df, aes(x = message_length, fill = label)) +
  geom_histogram(bins = 50, position = "identity", alpha = 0.7) +
  labs(
    title = "Distribución de la Longitud del Mensaje",
    x = "Longitud",
    y = "Frecuencia"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("ham" = "skyblue", "spam" = "salmon"))
```

# Modelo regresión logística

```{r}
#| message: false
#| warning: false
# Corpus columna mensajes
corpus <- Corpus(VectorSource(df$message))

# Limpieza
corpus_clean <- corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stemDocument) %>%
  tm_map(stripWhitespace)

# Document-Term Matrix (DTM)
dtm <- DocumentTermMatrix(corpus_clean)

# Reducir la dimensionalidad
sparse_dtm <- removeSparseTerms(dtm, 0.999)

dim(sparse_dtm)

X <- as.data.frame(as.matrix(sparse_dtm))
X$label <- df$label
```

```{r}
set.seed(123)

split <- sample.split(X$label, SplitRatio = 0.80)
train_set <- subset(X, split == TRUE)
test_set <- subset(X, split == FALSE)
```

```{r}
#| echo: false
#| message: false
#| warning: false
# Entrenar el modelo logistico
log_reg_model <- glm(label ~ ., 
                     data = train_set, family = "binomial")

summary(log_reg_model)
```

```{r}
#| message: false
#| warning: false
# Predicciones
predicted_probs <- predict(log_reg_model, 
                           newdata = test_set, type = "response")

# Convertir a clases - umbral de 0.5
predicted_labels <- ifelse(predicted_probs > 0.5, "spam", "ham")
predicted_labels <- as.factor(predicted_labels)

# Matriz de confusión
confusionMatrix(data = predicted_labels, reference = test_set$label, positive = "spam")
```

```{r}
#| message: false
#| warning: false
roc_obj <- roc(test_set$label, predicted_probs)

# AUC
auc_value <- auc(roc_obj); auc_value

# Curva ROC
ggroc(roc_obj, colour = 'orange', size = 1) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="grey", linetype="dashed") +
  labs(
    title = "Curva ROC",
    x = "Especificidad",
    y = "Sensibilidad"
  ) +
  theme_minimal()
```

# Modelo Naive-Bayes

```{r}
#| message: false
#| warning: false
# Entrenar modelo
X_train <- train_set[, -ncol(train_set)]
y_train <- train_set$label

nb_model <- naiveBayes(x = X_train, y = y_train, laplace = TRUE)
```

```{r}
#| echo: false
#| message: false
#| warning: false
X_test <- test_set[, -ncol(test_set)]
y_test <- test_set$label

# Predicción
nb_predicted_labels <- predict(nb_model, newdata = X_test)

# Matriz de confusión y métricas
confusionMatrix(data = nb_predicted_labels, reference = y_test, positive = "spam")
```

```{r}
#| message: false
#| warning: false
# Curva ROC
nb_predicted_probs <- predict(nb_model, newdata = X_test, type = "raw")

nb_roc_obj <- roc(y_test, nb_predicted_probs[, "spam"])

# AUC
nb_auc_value <- auc(nb_roc_obj)
print(paste("AUC del modelo Naive-Bayes:", round(nb_auc_value, 4)))

# Curva ROC
ggroc(nb_roc_obj, colour = 'blue', size = 1) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="grey", linetype="dashed") +
  labs(
    title = "Curva ROC - Naive Bayes",
    x = "1 - Especificidad",
    y = "Sensibilidad"
  ) +
  theme_minimal()
```

# Naive-Bayes con otra prior

Se usara una prior de 50%/50%

```{r}
#| message: false
#| warning: false
# Entrenar modelo
nb_model_prior <- naiveBayes(x = X_train, y = y_train,
                           prior = c(ham = 0.5, spam = 0.5))

# Evaluar modelo
nb_predicted_labels_prior <- predict(nb_model_prior, newdata = X_test)
confusionMatrix(data = nb_predicted_labels_prior, reference = y_test, positive = "spam")
```

# Bernoulli Naive-Bayes

Esta variante no considera la frecuencia de las palabras, sino únicamente su presencia o ausencia.

```{r}
#| message: false
#| warning: false
X_bernoulli <- X %>%
  mutate(across(-label, ~as.factor(ifelse(. > 0, 1, 0))))

train_set_bernoulli <- subset(X_bernoulli, split == TRUE)
test_set_bernoulli <- subset(X_bernoulli, split == FALSE)
```

```{r}
# Entrenar modelo
X_train_bernoulli <- train_set_bernoulli[, -ncol(train_set_bernoulli)]
y_train_bernoulli <- train_set_bernoulli$label

nb_model_bernoulli <- naiveBayes(x = X_train_bernoulli, y = y_train_bernoulli)

# Evaluar modelo
X_test_bernoulli <- test_set_bernoulli[, -ncol(test_set_bernoulli)]
y_test_bernoulli <- test_set_bernoulli$label
nb_predicted_labels_bernoulli <- predict(nb_model_bernoulli, newdata = X_test_bernoulli)

confusionMatrix(data = nb_predicted_labels_bernoulli, reference = y_test_bernoulli, positive = "spam")
```

# Tabla comparativa de resultados

```{r}
#| message: false
#| warning: false
# Valores AUC
# modelo Naive Bayes con Prior
nb_predicted_probs_prior <- predict(nb_model_prior, newdata = X_test, type = "raw")
roc_obj_prior <- roc(y_test, nb_predicted_probs_prior[, "spam"])
auc_value_prior <- auc(roc_obj_prior)

# modelo Naive Bayes Bernoulli
nb_predicted_probs_bernoulli <- predict(nb_model_bernoulli, newdata = X_test_bernoulli, type = "raw")
roc_obj_bernoulli <- roc(y_test_bernoulli, nb_predicted_probs_bernoulli[, "spam"])
auc_value_bernoulli <- auc(roc_obj_bernoulli)


# Metricas Matriz de confución
log_reg_metrics <- confusionMatrix(data = predicted_labels, reference = test_set$label, positive = "spam")
nb_metrics <- confusionMatrix(data = nb_predicted_labels, reference = y_test, positive = "spam")
nb_prior_metrics <- confusionMatrix(data = nb_predicted_labels_prior, reference = y_test, positive = "spam")
nb_bernoulli_metrics <- confusionMatrix(data = nb_predicted_labels_bernoulli, reference = y_test_bernoulli, positive = "spam")

comparison_df <- data.frame(
  Modelo = c("Regresión Logística", "Naive Bayes Multinomial", "NB con Prior 50/50", "Naive Bayes Bernoulli"),
  Accuracy = c(
    log_reg_metrics$overall["Accuracy"],
    nb_metrics$overall["Accuracy"],
    nb_prior_metrics$overall["Accuracy"],
    nb_bernoulli_metrics$overall["Accuracy"]
  ),
  Precision = c(
    log_reg_metrics$byClass["Precision"],
    nb_metrics$byClass["Precision"],
    nb_prior_metrics$byClass["Precision"],
    nb_bernoulli_metrics$byClass["Precision"]
  ),
  Sensibilidad = c(
    log_reg_metrics$byClass["Sensitivity"],
    nb_metrics$byClass["Sensitivity"],
    nb_prior_metrics$byClass["Sensitivity"],
    nb_bernoulli_metrics$byClass["Sensitivity"]
  ),
  AUC = c(
    auc_value,
    nb_auc_value,
    auc_value_prior,
    auc_value_bernoulli
  )
)

knitr::kable(comparison_df,
             digits = 4)
```
